{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics, svm, naive_bayes\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract labels from files\n",
    "def extract_labels(file_path):\n",
    "    with open(file_path) as file_labels:\n",
    "\n",
    "        file_lines = file_labels.readlines()\n",
    "\n",
    "        file_shape_labels= [None] * len(file_lines)\n",
    "        file_position_labels = [None] * len(file_lines)\n",
    "        file_phoneme_labels = [None] * len(file_lines)\n",
    "        file_second_phoneme_label = [None] * len(file_lines)\n",
    "        \n",
    "        for i, line in enumerate(file_lines):\n",
    "            file_line = line.split()\n",
    "\n",
    "            file_shape_labels[i]  = int(file_line[1])\n",
    "            file_position_labels[i] = int(file_line[2])\n",
    "            file_phoneme_labels[i] = int(file_line[3])\n",
    "            file_second_phoneme_label[i] = int(file_line[4])\n",
    "            \n",
    "    return np.array(file_shape_labels), np.array(file_position_labels), np.array(file_phoneme_labels), np.array(file_second_phoneme_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funtion to randomly shuffle data\n",
    "def shuffle_data(images, shape_labels, position_labels, phoneme_labels, second_phoneme_labels):\n",
    "    #index = np.arange(len(labels))\n",
    "    #np.shuffle(index)\n",
    "    index = np.random.choice(np.arange(len(phoneme_labels)), replace = False, size = len(phoneme_labels))\n",
    "    \n",
    "    shuffled_images = images[index]\n",
    "    shuffled_shape_labels = shape_labels[index]\n",
    "    shuffled_position_labels = position_labels[index]\n",
    "    shuffled_phoneme_labels = phoneme_labels[index]\n",
    "    shuffled_second_phoneme_labels = second_phoneme_labels[index]\n",
    "    return shuffled_images, shuffled_shape_labels, shuffled_position_labels, shuffled_phoneme_labels, shuffled_second_phoneme_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to split data\n",
    "def split_data(data, split_ratio=0.9):\n",
    "    partition = round(len(data) * split_ratio)\n",
    "    \n",
    "    train = data[:partition]\n",
    "    test = data[partition:]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to prepare dataset to input network\n",
    "def create_dataset(image_dir):\n",
    "    dataset = []\n",
    "    for image_name in os.listdir(image_dir):\n",
    "        image = Image.open(image_dir + image_name)\n",
    "        image_as_array = np.asarray(image)\n",
    "        dataset.append(image_as_array)\n",
    "    return np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to concatenate outputs of two networks into single vector\n",
    "def join_outputs(out1, out2):\n",
    "    joint_output = []\n",
    "    for i in range(len(out1)):\n",
    "        joint = np.concatenate((out1[i],out2[i]))\n",
    "        joint_output.append(joint)\n",
    "    return np.array(joint_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot training and validation loss and accuracy\n",
    "#Obtained from https://www.tensorflow.org/tutorials/images/classification\n",
    "def plot_training_results(history):\n",
    "    epochs = 10\n",
    "    loss=history.history['loss']\n",
    "    val_loss=history.history['val_loss']\n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the data augmentation layer that will go in at the start of the networks\n",
    "#Obtained from https://www.tensorflow.org/tutorials/images/classification\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open image folders\n",
    "consonants_dir = os.path.join('/Users/User/Desktop/MSc Project/English Cued Speech/ConsonantImages/')\n",
    "vowels_dir = os.path.join('/Users/User/Desktop/MSc Project/English Cued Speech/VowelImages/')\n",
    "combined_dir = os.path.join('/Users/User/Desktop/MSc Project/English Cued Speech/PhonemeImages/')\n",
    "\n",
    "#Open label files\n",
    "consonant_labels = \"/Users/User/Desktop/MSc Project/English Cued Speech/Labels_Consonant.txt\"\n",
    "vowel_labels = \"/Users/User/Desktop/MSc Project/English Cued Speech/Labels_Vowel.txt\"\n",
    "combined_labels = \"/Users/User/Desktop/MSc Project/English Cued Speech/Labels_All.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract labels\n",
    "(vowel_shape_labels, vowel_position_labels, vowel_phoneme_labels, not_used) = extract_labels(vowel_labels)\n",
    "(consonant_shape_labels, consonant_position_labels, consonant_phoneme_labels, or_this) = extract_labels(consonant_labels)\n",
    "(combined_shape_labels, combined_position_labels, combined_consonant_labels, combined_vowel_labels) = extract_labels(combined_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consonants Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare images of consonants to input into network\n",
    "consonant_images = create_dataset(consonants_dir)\n",
    "consonant_images = consonant_images.reshape(len(consonant_images), 256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly shuffle consonant images and labels\n",
    "shuffled_consonants, shuffled_consonant_shape_labels, shuffled_consonant_position_labels, shuffled_consonant_phoneme_labels, nor_this = shuffle_data(consonant_images, consonant_shape_labels, consonant_position_labels, consonant_phoneme_labels, or_this)\n",
    "\n",
    "#Split training and test data\n",
    "consonant_train, consonant_test = split_data(shuffled_consonants)\n",
    "consonant_shape_labels_train, consonant_shape_labels_test = split_data(shuffled_consonant_shape_labels)\n",
    "consonant_position_labels_train, consonant_position_labels_test = split_data(shuffled_consonant_position_labels)\n",
    "consonant_phoneme_labels_train, consonant_phoneme_labels_test = split_data(shuffled_consonant_phoneme_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "43/43 [==============================] - 53s 1s/step - loss: 2.2967 - accuracy: 0.2031\n",
      "Epoch 2/7\n",
      "43/43 [==============================] - 52s 1s/step - loss: 1.7901 - accuracy: 0.3388\n",
      "Epoch 3/7\n",
      "43/43 [==============================] - 53s 1s/step - loss: 1.2507 - accuracy: 0.5745\n",
      "Epoch 4/7\n",
      "43/43 [==============================] - 52s 1s/step - loss: 0.7815 - accuracy: 0.7413\n",
      "Epoch 5/7\n",
      "43/43 [==============================] - 52s 1s/step - loss: 0.5291 - accuracy: 0.8147\n",
      "Epoch 6/7\n",
      "43/43 [==============================] - 54s 1s/step - loss: 0.3507 - accuracy: 0.8836\n",
      "Epoch 7/7\n",
      "43/43 [==============================] - 56s 1s/step - loss: 0.2536 - accuracy: 0.9222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c5919de388>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build the network to recognise hand shape\n",
    "hand_shape_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(256, 256, 3)),\n",
    "  tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(9, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compile the network\n",
    "hand_shape_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train the network\n",
    "hand_shape_model.fit(consonant_train, consonant_shape_labels_train, epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_training_results(hand_shape_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 337ms/step - loss: 0.5808 - accuracy: 0.8400\n",
      "Test loss: 0.5808157324790955, Test accuracy: 83.99999737739563\n"
     ]
    }
   ],
   "source": [
    "#Test the network and print it's performance\n",
    "hand_shape_test_loss, hand_shape_test_accuracy = hand_shape_model.evaluate(consonant_test, consonant_shape_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(hand_shape_test_loss, hand_shape_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "43/43 [==============================] - 62s 1s/step - loss: 3.0167 - accuracy: 0.1023\n",
      "Epoch 2/7\n",
      "43/43 [==============================] - 54s 1s/step - loss: 2.7047 - accuracy: 0.2046\n",
      "Epoch 3/7\n",
      "43/43 [==============================] - 56s 1s/step - loss: 2.2637 - accuracy: 0.3447\n",
      "Epoch 4/7\n",
      "43/43 [==============================] - 58s 1s/step - loss: 1.7294 - accuracy: 0.4863\n",
      "Epoch 5/7\n",
      "43/43 [==============================] - 63s 1s/step - loss: 1.3494 - accuracy: 0.5678\n",
      "Epoch 6/7\n",
      "43/43 [==============================] - 58s 1s/step - loss: 1.0945 - accuracy: 0.6264\n",
      "Epoch 7/7\n",
      "43/43 [==============================] - 53s 1s/step - loss: 0.8725 - accuracy: 0.7079\n"
     ]
    }
   ],
   "source": [
    "#Build network to recognise consonant phoneme\n",
    "consonant_phoneme_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(256, 256, 3)),\n",
    "  tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(25, activation='softmax')\n",
    "])\n",
    "\n",
    "#Complie the network\n",
    "consonant_phoneme_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train the network\n",
    "#consonant_phoneme_history = \n",
    "consonant_phoneme_history = consonant_phoneme_model.fit(consonant_train, consonant_phoneme_labels_train, epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_training_results(consonant_phoneme_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 308ms/step - loss: 1.6952 - accuracy: 0.5133\n",
      "Test loss: 1.6952332258224487, Test accuracy: 51.33333206176758\n"
     ]
    }
   ],
   "source": [
    "#Test the network and print it's performance\n",
    "consonant_phoneme_test_loss, consonant_phoneme_test_accuracy = consonant_phoneme_model.evaluate(consonant_test, consonant_phoneme_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(consonant_phoneme_test_loss, consonant_phoneme_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain decisions from both networks and concatenate into a single decision vector\n",
    "hand_shape_decision = hand_shape_model(consonant_train)\n",
    "\n",
    "consonant_phoneme_decision = consonant_phoneme_model(consonant_train)\n",
    "\n",
    "consonant_decision = join_outputs(hand_shape_decision, consonant_phoneme_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain test vectors to test network on\n",
    "hand_shape_decision_test = hand_shape_model(consonant_test)\n",
    "\n",
    "consonant_phoneme_decision_test = consonant_phoneme_model(consonant_test)\n",
    "\n",
    "consonant_decision_test = join_outputs(hand_shape_decision_test, consonant_phoneme_decision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 3.1427 - accuracy: 0.0563\n",
      "Epoch 2/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.9714 - accuracy: 0.3647\n",
      "Epoch 3/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.7593 - accuracy: 0.4996\n",
      "Epoch 4/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.5058 - accuracy: 0.5278\n",
      "Epoch 5/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.2280 - accuracy: 0.5434\n",
      "Epoch 6/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.9575 - accuracy: 0.5797\n",
      "Epoch 7/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.7158 - accuracy: 0.6086\n",
      "Epoch 8/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5120 - accuracy: 0.6338\n",
      "Epoch 9/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3496 - accuracy: 0.6590\n",
      "Epoch 10/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2192 - accuracy: 0.6909\n",
      "Epoch 11/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1174 - accuracy: 0.7102\n",
      "Epoch 12/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0330 - accuracy: 0.7346\n",
      "Epoch 13/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9633 - accuracy: 0.7398\n",
      "Epoch 14/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.9055 - accuracy: 0.7450\n",
      "Epoch 15/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.8567 - accuracy: 0.7502\n",
      "Epoch 16/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.8151 - accuracy: 0.7643\n",
      "Epoch 17/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7788 - accuracy: 0.7717\n",
      "Epoch 18/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7491 - accuracy: 0.7732\n",
      "Epoch 19/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.7227 - accuracy: 0.7769: 0s - loss: 0.7453 - accuracy: 0.78\n",
      "Epoch 20/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6984 - accuracy: 0.7917\n",
      "Epoch 21/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6792 - accuracy: 0.7902\n",
      "Epoch 22/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6603 - accuracy: 0.7924\n",
      "Epoch 23/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6438 - accuracy: 0.7969\n",
      "Epoch 24/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6298 - accuracy: 0.8043\n",
      "Epoch 25/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.8006\n",
      "Epoch 26/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.6051 - accuracy: 0.8021\n",
      "Epoch 27/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.8095\n",
      "Epoch 28/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5845 - accuracy: 0.8036\n",
      "Epoch 29/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.8087\n",
      "Epoch 30/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.8117\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c593adc8c8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build network to make final decision of phoneme\n",
    "consonant_decision_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(16, activation='relu'),\n",
    "  tf.keras.layers.Dense(25, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compile network\n",
    "consonant_decision_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train network\n",
    "consonant_decision_model.fit(consonant_decision, consonant_phoneme_labels_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 1.4518 - accuracy: 0.5000\n",
      "Test loss: 1.4517922401428223, Test accuracy: 50.0\n"
     ]
    }
   ],
   "source": [
    "#Test network and print result\n",
    "consonant_test_loss, consonant_test_accuracy = consonant_decision_model.evaluate(consonant_decision_test, consonant_phoneme_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(consonant_test_loss, consonant_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build SVM classifier for consonant\n",
    "consonant_svm = svm.SVC(kernel='linear')\n",
    "\n",
    "consonant_svm.fit(consonant_decision, consonant_phoneme_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.333333333333336\n"
     ]
    }
   ],
   "source": [
    "#Test SVM classifier and print accuracy\n",
    "svm_consonant_decision = consonant_svm.predict(consonant_decision_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(consonant_phoneme_labels_test, svm_consonant_decision)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build Naive-Bayes classifier for consonant\n",
    "consonant_nb = naive_bayes.GaussianNB()\n",
    "\n",
    "consonant_nb.fit(consonant_decision, consonant_phoneme_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 32.666666666666664\n"
     ]
    }
   ],
   "source": [
    "#Test Naive-Bayes classifier and print accuracy\n",
    "nb_consonant_decision = consonant_nb.predict(consonant_decision_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(consonant_phoneme_labels_test, nb_consonant_decision)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
