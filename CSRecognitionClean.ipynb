{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract labels from files\n",
    "def extract_labels(file_path):\n",
    "    with open(file_path) as file_labels:\n",
    "\n",
    "        file_lines = file_labels.readlines()\n",
    "\n",
    "        file_shape_labels= [None] * len(file_lines)\n",
    "        file_position_labels = [None] * len(file_lines)\n",
    "        file_phoneme_labels = [None] * len(file_lines)\n",
    "        file_second_phoneme_label = [None] * len(file_lines)\n",
    "        \n",
    "        for i, line in enumerate(file_lines):\n",
    "            file_line = line.split()\n",
    "\n",
    "            file_shape_labels[i]  = int(file_line[1])\n",
    "            file_position_labels[i] = int(file_line[2])\n",
    "            file_phoneme_labels[i] = int(file_line[3])\n",
    "            file_second_phoneme_label[i] = int(file_line[4])\n",
    "            \n",
    "    return np.array(file_shape_labels), np.array(file_position_labels), np.array(file_phoneme_labels), np.array(file_second_phoneme_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funtion to randomly shuffle data\n",
    "def shuffle_data(images, shape_labels, position_labels, phoneme_labels, second_phoneme_labels):\n",
    "    #index = np.arange(len(labels))\n",
    "    #np.shuffle(index)\n",
    "    index = np.random.choice(np.arange(len(phoneme_labels)), replace = False, size = len(phoneme_labels))\n",
    "    \n",
    "    shuffled_images = images[index]\n",
    "    shuffled_shape_labels = shape_labels[index]\n",
    "    shuffled_position_labels = position_labels[index]\n",
    "    shuffled_phoneme_labels = phoneme_labels[index]\n",
    "    shuffled_second_phoneme_labels = second_phoneme_labels[index]\n",
    "    return shuffled_images, shuffled_shape_labels, shuffled_position_labels, shuffled_phoneme_labels, shuffled_second_phoneme_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to split data\n",
    "def split_data(data, split_ratio=0.9):\n",
    "    partition = round(len(data) * split_ratio)\n",
    "    \n",
    "    train = data[:partition]\n",
    "    test = data[partition:]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to prepare dataset to input network\n",
    "def create_dataset(image_dir):\n",
    "    dataset = []\n",
    "    for image_name in os.listdir(image_dir):\n",
    "        image = Image.open(image_dir + image_name)\n",
    "        image_as_array = np.asarray(image)\n",
    "        dataset.append(image_as_array)\n",
    "    return np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to prepare dataset as grey images to input network\n",
    "def create_grey_dataset(image_dir):\n",
    "    grey_dataset = []\n",
    "    for image_name in os.listdir(image_dir):\n",
    "        image = Image.open(image_dir + image_name)\n",
    "        image_as_array = np.asarray(image)\n",
    "        r, g, b = image_as_array[:,:,0], image_as_array[:,:,1], image_as_array[:,:,2]\n",
    "        grey_image = (0.3*r) + (0.59*g) +(0.11*b)\n",
    "        grey_dataset.append(grey_image)\n",
    "    return np.array(grey_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to concatenate outputs of two networks into single vector\n",
    "def join_outputs(out1, out2):\n",
    "    joint_output = []\n",
    "    for i in range(len(out1)):\n",
    "        joint = np.concatenate((out1[i],out2[i]))\n",
    "        joint_output.append(joint)\n",
    "    return np.array(joint_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open image folders\n",
    "consonants_dir = os.path.join('/Users/User/Desktop/MSc Project/English Cued Speech/ConsonantImages/')\n",
    "vowels_dir = os.path.join('/Users/User/Desktop/MSc Project/English Cued Speech/VowelImages/')\n",
    "combined_dir = os.path.join('/Users/User/Desktop/MSc Project/English Cued Speech/PhonemeImages/')\n",
    "\n",
    "#Open label files\n",
    "consonant_labels = \"/Users/User/Desktop/MSc Project/English Cued Speech/Labels_Consonant.txt\"\n",
    "vowel_labels = \"/Users/User/Desktop/MSc Project/English Cued Speech/Labels_Vowel.txt\"\n",
    "combined_labels = \"/Users/User/Desktop/MSc Project/English Cued Speech/Labels_All.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract labels\n",
    "(vowel_shape_labels, vowel_position_labels, vowel_phoneme_labels, not_used) = extract_labels(vowel_labels)\n",
    "(consonant_shape_labels, consonant_position_labels, consonant_phoneme_labels, or_this) = extract_labels(consonant_labels)\n",
    "(combined_shape_labels, combined_position_labels, combined_consonant_labels, combined_vowel_labels) = extract_labels(combined_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vowels Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare images of vowels to input into network\n",
    "vowel_images = create_dataset(vowels_dir)\n",
    "vowel_images = vowel_images.reshape(len(vowel_images), 256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly shuffle vowel images and labels\n",
    "shuffled_vowels, shuffled_vowel_shape_labels, shuffled_vowel_position_labels, shuffled_vowel_phoneme_labels, non_used = shuffle_data(vowel_images, vowel_shape_labels, vowel_position_labels, vowel_phoneme_labels, not_used)\n",
    "\n",
    "#Split training and test data\n",
    "vowel_train, vowel_test = split_data(shuffled_vowels)\n",
    "vowel_shape_labels_train, vowel_shape_labels_test = split_data(shuffled_vowel_shape_labels)\n",
    "vowel_position_labels_train, vowel_position_labels_test = split_data(shuffled_vowel_position_labels)\n",
    "vowel_phoneme_labels_train, vowel_phoneme_labels_test = split_data(shuffled_vowel_phoneme_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "33/33 [==============================] - 34s 1s/step - loss: 0.8214 - accuracy: 0.7274\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 36s 1s/step - loss: 0.1983 - accuracy: 0.9408\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 36s 1s/step - loss: 0.1322 - accuracy: 0.9709\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 37s 1s/step - loss: 0.1150 - accuracy: 0.9728\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 37s 1s/step - loss: 0.0898 - accuracy: 0.9835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dec38de0c8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build the network to recognise hand position\n",
    "hand_position_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(256, 256, 3)),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compile the network\n",
    "hand_position_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train the network\n",
    "hand_position_model.fit(vowel_train, vowel_position_labels_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 295ms/step - loss: 0.1863 - accuracy: 0.9652\n",
      "Test loss: 0.18631866574287415, Test accuracy: 96.52174115180969\n"
     ]
    }
   ],
   "source": [
    "#Test the network and print it's performance\n",
    "hand_position_test_loss, hand_position_test_accuracy = hand_position_model.evaluate(vowel_test, vowel_position_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(hand_position_test_loss, hand_position_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "33/33 [==============================] - 35s 1s/step - loss: 1.6215 - accuracy: 0.5092\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 35s 1s/step - loss: 1.0689 - accuracy: 0.6130\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 36s 1s/step - loss: 0.9317 - accuracy: 0.6440\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 36s 1s/step - loss: 0.7878 - accuracy: 0.6838\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 36s 1s/step - loss: 0.7738 - accuracy: 0.6925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dec4b1b288>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build network to recognise vowel phoneme\n",
    "vowel_phoneme_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(256, 256, 3)),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(13, activation='softmax')\n",
    "])\n",
    "\n",
    "#Complie the network\n",
    "vowel_phoneme_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train the network\n",
    "vowel_phoneme_model.fit(vowel_train, vowel_phoneme_labels_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 314ms/step - loss: 0.8962 - accuracy: 0.6696\n",
      "Test loss: 0.8962281346321106, Test accuracy: 66.9565200805664\n"
     ]
    }
   ],
   "source": [
    "#Test the network and print it's performance\n",
    "vowel_phoneme_test_loss, vowel_phoneme_test_accuracy = vowel_phoneme_model.evaluate(vowel_test, vowel_phoneme_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(vowel_phoneme_test_loss, vowel_phoneme_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain decisions from both networks and concatenate into a single decision vector\n",
    "hand_position_decision = hand_position_model(vowel_train)\n",
    "\n",
    "vowel_phoneme_decision = vowel_phoneme_model(vowel_train)\n",
    "\n",
    "vowel_decision = join_outputs(hand_position_decision, vowel_phoneme_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain test vectors to test network on\n",
    "hand_position_decision_test = hand_position_model(vowel_test)\n",
    "\n",
    "vowel_phoneme_decision_test = vowel_phoneme_model(vowel_test)\n",
    "\n",
    "vowel_decision_test = join_outputs(hand_position_decision_test, vowel_phoneme_decision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.5144 - accuracy: 0.2211\n",
      "Epoch 2/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.3510 - accuracy: 0.2173\n",
      "Epoch 3/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.2358 - accuracy: 0.2173\n",
      "Epoch 4/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 2.1508 - accuracy: 0.2173\n",
      "Epoch 5/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 2.0855 - accuracy: 0.3298\n",
      "Epoch 6/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 2.0310 - accuracy: 0.4462\n",
      "Epoch 7/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.9806 - accuracy: 0.4462\n",
      "Epoch 8/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.9331 - accuracy: 0.4462\n",
      "Epoch 9/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.8837 - accuracy: 0.4462\n",
      "Epoch 10/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.8341 - accuracy: 0.4462\n",
      "Epoch 11/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.7833 - accuracy: 0.4462\n",
      "Epoch 12/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.7313 - accuracy: 0.4850\n",
      "Epoch 13/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.6795 - accuracy: 0.5907\n",
      "Epoch 14/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.6280 - accuracy: 0.6295\n",
      "Epoch 15/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.5773 - accuracy: 0.6411\n",
      "Epoch 16/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.5275 - accuracy: 0.6431\n",
      "Epoch 17/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.4804 - accuracy: 0.6431\n",
      "Epoch 18/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.4349 - accuracy: 0.6431\n",
      "Epoch 19/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.3926 - accuracy: 0.6431\n",
      "Epoch 20/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.3524 - accuracy: 0.6431\n",
      "Epoch 21/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.3153 - accuracy: 0.6431\n",
      "Epoch 22/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.2809 - accuracy: 0.6431\n",
      "Epoch 23/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.2492 - accuracy: 0.6431\n",
      "Epoch 24/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.2195 - accuracy: 0.6431\n",
      "Epoch 25/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.1917 - accuracy: 0.6440\n",
      "Epoch 26/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.1675 - accuracy: 0.6440\n",
      "Epoch 27/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.1443 - accuracy: 0.6440\n",
      "Epoch 28/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.1231 - accuracy: 0.6440\n",
      "Epoch 29/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.1034 - accuracy: 0.6440\n",
      "Epoch 30/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.0854 - accuracy: 0.6440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dec5b7f108>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build network to make final decision of phoneme\n",
    "vowel_decision_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(16, activation='sigmoid'),\n",
    "  tf.keras.layers.Dense(13, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compile network\n",
    "vowel_decision_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train network\n",
    "vowel_decision_model.fit(vowel_decision, vowel_phoneme_labels_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 [======>.......................] - ETA: 0s - loss: 1.2036 - accuracy: 0.5312WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0021s). Check your callbacks.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1.1102 - accuracy: 0.6522\n",
      "Test loss: 1.1102010011672974, Test accuracy: 65.21739363670349\n"
     ]
    }
   ],
   "source": [
    "#Test network and print result\n",
    "vowel_test_loss, vowel_test_accuracy = vowel_decision_model.evaluate(vowel_decision_test, vowel_phoneme_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(vowel_test_loss, vowel_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consonants Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare images of consonants to input into network\n",
    "consonant_images = create_dataset(consonants_dir)\n",
    "consonant_images = consonant_images.reshape(len(consonant_images), 256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly shuffle consonant images and labels\n",
    "shuffled_consonants, shuffled_consonant_shape_labels, shuffled_consonant_position_labels, shuffled_consonant_phoneme_labels, nor_this = shuffle_data(consonant_images, consonant_shape_labels, consonant_position_labels, consonant_phoneme_labels, or_this)\n",
    "\n",
    "#Split training and test data\n",
    "consonant_train, consonant_test = split_data(shuffled_consonants)\n",
    "consonant_shape_labels_train, consonant_shape_labels_test = split_data(shuffled_consonant_shape_labels)\n",
    "consonant_position_labels_train, consonant_position_labels_test = split_data(shuffled_consonant_position_labels)\n",
    "consonant_phoneme_labels_train, consonant_phoneme_labels_test = split_data(shuffled_consonant_phoneme_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "43/43 [==============================] - 47s 1s/step - loss: 2.0183 - accuracy: 0.2098\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 46s 1s/step - loss: 1.6329 - accuracy: 0.4114\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 33s 765ms/step - loss: 1.2034 - accuracy: 0.5930\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 53s 1s/step - loss: 0.8612 - accuracy: 0.7124\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 49s 1s/step - loss: 0.6225 - accuracy: 0.8058\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dec5d38688>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build the network to recognise hand shape\n",
    "hand_shape_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(256, 256, 3)),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(9, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compile the networ\n",
    "hand_shape_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train the network\n",
    "hand_shape_model.fit(consonant_train, consonant_shape_labels_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 337ms/step - loss: 0.7584 - accuracy: 0.7000\n",
      "Test loss: 0.7584484219551086, Test accuracy: 69.9999988079071\n"
     ]
    }
   ],
   "source": [
    "#Test the network and print it's performance\n",
    "hand_shape_test_loss, hand_shape_test_accuracy = hand_shape_model.evaluate(consonant_test, consonant_shape_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(hand_shape_test_loss, hand_shape_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "43/43 [==============================] - 46s 1s/step - loss: 2.9272 - accuracy: 0.1282\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 47s 1s/step - loss: 2.5543 - accuracy: 0.2609\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 46s 1s/step - loss: 2.1560 - accuracy: 0.3640\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 47s 1s/step - loss: 1.7239 - accuracy: 0.4841\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 45s 1s/step - loss: 1.3917 - accuracy: 0.5856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dec5ea9448>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build network to recognise consonant phoneme\n",
    "consonant_phoneme_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(256, 256, 3)),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(25, activation='softmax')\n",
    "])\n",
    "\n",
    "#Complie the network\n",
    "consonant_phoneme_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train the network\n",
    "consonant_phoneme_model.fit(consonant_train, consonant_phoneme_labels_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 2s 336ms/step - loss: 1.9401 - accuracy: 0.4200\n",
      "Test loss: 1.9401021003723145, Test accuracy: 41.999998688697815\n"
     ]
    }
   ],
   "source": [
    "#Test the network and print it's performance\n",
    "consonant_phoneme_test_loss, consonant_phoneme_test_accuracy = consonant_phoneme_model.evaluate(consonant_test, consonant_phoneme_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(consonant_phoneme_test_loss, consonant_phoneme_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain decisions from both networks and concatenate into a single decision vector\n",
    "hand_shape_decision = hand_shape_model(consonant_train)\n",
    "\n",
    "consonant_phoneme_decision = consonant_phoneme_model(consonant_train)\n",
    "\n",
    "consonant_decision = join_outputs(hand_shape_decision, consonant_phoneme_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain test vectors to test network on\n",
    "hand_shape_decision_test = hand_shape_model(consonant_test)\n",
    "\n",
    "consonant_phoneme_decision_test = consonant_phoneme_model(consonant_test)\n",
    "\n",
    "consonant_decision_test = join_outputs(hand_shape_decision_test, consonant_phoneme_decision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 3.1522 - accuracy: 0.0726\n",
      "Epoch 2/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 3.0387 - accuracy: 0.0734\n",
      "Epoch 3/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.9704 - accuracy: 0.1171\n",
      "Epoch 4/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.9279 - accuracy: 0.1164\n",
      "Epoch 5/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.8960 - accuracy: 0.1164\n",
      "Epoch 6/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.8694 - accuracy: 0.1231\n",
      "Epoch 7/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.8446 - accuracy: 0.1290\n",
      "Epoch 8/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.8190 - accuracy: 0.1534\n",
      "Epoch 9/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.7919 - accuracy: 0.1875\n",
      "Epoch 10/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.7632 - accuracy: 0.1987: 0s - loss: 2.7482 - accuracy: 0.19\n",
      "Epoch 11/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.7320 - accuracy: 0.2202\n",
      "Epoch 12/30\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 2.6989 - accuracy: 0.2298\n",
      "Epoch 13/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.6621 - accuracy: 0.2572\n",
      "Epoch 14/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.6236 - accuracy: 0.3069\n",
      "Epoch 15/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.5816 - accuracy: 0.3136\n",
      "Epoch 16/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.5384 - accuracy: 0.3766\n",
      "Epoch 17/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.4923 - accuracy: 0.3981\n",
      "Epoch 18/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.4444 - accuracy: 0.4033\n",
      "Epoch 19/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.3957 - accuracy: 0.4203\n",
      "Epoch 20/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.3457 - accuracy: 0.4173\n",
      "Epoch 21/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.2955 - accuracy: 0.4285\n",
      "Epoch 22/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.2453 - accuracy: 0.4299\n",
      "Epoch 23/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.1950 - accuracy: 0.4485\n",
      "Epoch 24/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.1463 - accuracy: 0.4566\n",
      "Epoch 25/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.0985 - accuracy: 0.4492\n",
      "Epoch 26/30\n",
      "43/43 [==============================] - ETA: 0s - loss: 2.0527 - accuracy: 0.46 - 0s 2ms/step - loss: 2.0512 - accuracy: 0.4648\n",
      "Epoch 27/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.0062 - accuracy: 0.4722\n",
      "Epoch 28/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.9622 - accuracy: 0.4796\n",
      "Epoch 29/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.9199 - accuracy: 0.4907\n",
      "Epoch 30/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.8791 - accuracy: 0.4989\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dec6023488>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build network to make final decision of phoneme\n",
    "consonant_decision_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(16, activation='sigmoid'),\n",
    "  tf.keras.layers.Dense(25, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compile network\n",
    "consonant_decision_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train network\n",
    "consonant_decision_model.fit(consonant_decision, consonant_phoneme_labels_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/5 [=====>........................] - ETA: 0s - loss: 2.0801 - accuracy: 0.3438WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_test_batch_end` time: 0.0018s). Check your callbacks.\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 2.0551 - accuracy: 0.3867\n",
      "Test loss: 2.0550689697265625, Test accuracy: 38.66666555404663\n"
     ]
    }
   ],
   "source": [
    "#Test network and print result\n",
    "consonant_test_loss, consonant_test_accuracy = consonant_decision_model.evaluate(consonant_decision_test, consonant_phoneme_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(consonant_test_loss, consonant_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grey Vowels Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert images of consonants to greyscale and prepare to input into network\n",
    "grey_vowel_images = create_grey_dataset(vowels_dir)\n",
    "grey_vowel_images = grey_vowel_images.reshape(len(grey_vowel_images), 256, 256, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly shuffle consonant images and labels\n",
    "grey_shuffled_vowels, grey_shuffled_vowel_shape_labels, grey_shuffled_vowel_position_labels, grey_shuffled_vowel_phoneme_labels, grey_non_used = shuffle_data(grey_vowel_images, vowel_shape_labels, vowel_position_labels, vowel_phoneme_labels, not_used)\n",
    "\n",
    "#Split training and test data\n",
    "grey_vowel_train, grey_vowel_test = split_data(grey_shuffled_vowels)\n",
    "grey_vowel_shape_labels_train, grey_vowel_shape_labels_test = split_data(grey_shuffled_vowel_shape_labels)\n",
    "grey_vowel_position_labels_train, grey_vowel_position_labels_test = split_data(grey_shuffled_vowel_position_labels)\n",
    "grey_vowel_phoneme_labels_train, grey_vowel_phoneme_labels_test = split_data(grey_shuffled_vowel_phoneme_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "33/33 [==============================] - 30s 914ms/step - loss: 0.7084 - accuracy: 0.7633\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 32s 963ms/step - loss: 0.2104 - accuracy: 0.9399\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 30s 916ms/step - loss: 0.1458 - accuracy: 0.9622\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 30s 922ms/step - loss: 0.1116 - accuracy: 0.9748\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 30s 919ms/step - loss: 0.0854 - accuracy: 0.9835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dec64484c8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build the network to recognise hand shape\n",
    "grey_hand_position_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(256, 256, 1)),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(9, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compile the networ\n",
    "grey_hand_position_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train the network\n",
    "grey_hand_position_model.fit(grey_vowel_train, grey_vowel_position_labels_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 251ms/step - loss: 0.1832 - accuracy: 0.9652\n",
      "Test loss: 0.18320411443710327, Test accuracy: 96.52174115180969\n"
     ]
    }
   ],
   "source": [
    "#Test the network and print it's performance\n",
    "grey_hand_position_test_loss, grey_hand_position_test_accuracy = grey_hand_position_model.evaluate(grey_vowel_test, grey_vowel_position_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(grey_hand_position_test_loss, grey_hand_position_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "33/33 [==============================] - 31s 937ms/step - loss: 1.8695 - accuracy: 0.4423\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 31s 936ms/step - loss: 1.1885 - accuracy: 0.6120\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 31s 941ms/step - loss: 0.9571 - accuracy: 0.6547\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 31s 930ms/step - loss: 0.8026 - accuracy: 0.6916\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 30s 913ms/step - loss: 0.6962 - accuracy: 0.7284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dec9bf58c8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build network to recognise consonant phoneme\n",
    "grey_vowel_phoneme_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(256, 256, 1)),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(25, activation='softmax')\n",
    "])\n",
    "\n",
    "#Complie the network\n",
    "grey_vowel_phoneme_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train the network\n",
    "grey_vowel_phoneme_model.fit(grey_vowel_train, grey_vowel_phoneme_labels_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 262ms/step - loss: 0.9839 - accuracy: 0.6174\n",
      "Test loss: 0.9839266538619995, Test accuracy: 61.739128828048706\n"
     ]
    }
   ],
   "source": [
    "#Test the network and print it's performance\n",
    "grey_vowel_phoneme_test_loss, grey_vowel_phoneme_test_accuracy = grey_vowel_phoneme_model.evaluate(grey_vowel_test, grey_vowel_phoneme_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(grey_vowel_phoneme_test_loss, grey_vowel_phoneme_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain decisions from both networks and concatenate into a single decision vector\n",
    "grey_hand_position_decision = grey_hand_position_model(grey_vowel_train)\n",
    "\n",
    "grey_vowel_phoneme_decision = grey_vowel_phoneme_model(grey_vowel_train)\n",
    "\n",
    "grey_vowel_decision = join_outputs(grey_hand_position_decision, grey_vowel_phoneme_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain test vectors to test network on\n",
    "grey_hand_position_decision_test = grey_hand_position_model(grey_vowel_test)\n",
    "\n",
    "grey_vowel_phoneme_decision_test = grey_vowel_phoneme_model(grey_vowel_test)\n",
    "\n",
    "grey_vowel_decision_test = join_outputs(grey_hand_position_decision_test, grey_vowel_phoneme_decision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 1/33 [..............................] - ETA: 0s - loss: 3.2404 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0016s vs `on_train_batch_begin` time: 0.0030s). Check your callbacks.\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 3.1564 - accuracy: 0.0582\n",
      "Epoch 2/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 2.8559 - accuracy: 0.1707\n",
      "Epoch 3/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 2.6193 - accuracy: 0.5131\n",
      "Epoch 4/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.4413 - accuracy: 0.4539\n",
      "Epoch 5/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 2.3060 - accuracy: 0.4539\n",
      "Epoch 6/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 2.2027 - accuracy: 0.4549\n",
      "Epoch 7/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.1242 - accuracy: 0.4549\n",
      "Epoch 8/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.0584 - accuracy: 0.4568\n",
      "Epoch 9/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 2.0002 - accuracy: 0.4568\n",
      "Epoch 10/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.9446 - accuracy: 0.4568\n",
      "Epoch 11/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.8907 - accuracy: 0.4568\n",
      "Epoch 12/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.8376 - accuracy: 0.5034\n",
      "Epoch 13/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.7832 - accuracy: 0.5422\n",
      "Epoch 14/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.7301 - accuracy: 0.5490\n",
      "Epoch 15/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.6775 - accuracy: 0.5509\n",
      "Epoch 16/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.6251 - accuracy: 0.5519\n",
      "Epoch 17/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.5739 - accuracy: 0.5548\n",
      "Epoch 18/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.5239 - accuracy: 0.6363\n",
      "Epoch 19/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.4763 - accuracy: 0.6499\n",
      "Epoch 20/30\n",
      "33/33 [==============================] - 0s 3ms/step - loss: 1.4306 - accuracy: 0.6508\n",
      "Epoch 21/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.3879 - accuracy: 0.6528\n",
      "Epoch 22/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.3471 - accuracy: 0.6547\n",
      "Epoch 23/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.3088 - accuracy: 0.6547\n",
      "Epoch 24/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.2732 - accuracy: 0.6547\n",
      "Epoch 25/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.2394 - accuracy: 0.6537\n",
      "Epoch 26/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.2091 - accuracy: 0.6537\n",
      "Epoch 27/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.1807 - accuracy: 0.6537\n",
      "Epoch 28/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.1543 - accuracy: 0.6537\n",
      "Epoch 29/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.1299 - accuracy: 0.6537\n",
      "Epoch 30/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.1084 - accuracy: 0.6537\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dec9be8488>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build network to make final decision of phoneme\n",
    "grey_vowel_decision_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(16, activation='sigmoid'),\n",
    "  tf.keras.layers.Dense(25, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compile network\n",
    "grey_vowel_decision_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train network\n",
    "grey_vowel_decision_model.fit(grey_vowel_decision, grey_vowel_phoneme_labels_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 1.2972 - accuracy: 0.5739\n",
      "Test loss: 1.2972033023834229, Test accuracy: 57.3913037776947\n"
     ]
    }
   ],
   "source": [
    "#Test network and print result\n",
    "grey_vowel_test_loss, grey_vowel_test_accuracy = grey_vowel_decision_model.evaluate(grey_vowel_decision_test, grey_vowel_phoneme_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(grey_vowel_test_loss, grey_vowel_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grey Consonants Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert images of consonants to greyscale and prepare to input into network\n",
    "grey_consonant_images = create_grey_dataset(consonants_dir)\n",
    "grey_consonant_images = grey_consonant_images.reshape(len(grey_consonant_images), 256, 256, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly shuffle consonant images and labels\n",
    "grey_shuffled_consonants, grey_shuffled_consonant_shape_labels, grey_shuffled_consonant_position_labels, grey_shuffled_consonant_phoneme_labels, grey_nor_this = shuffle_data(grey_consonant_images, consonant_shape_labels, consonant_position_labels, consonant_phoneme_labels, or_this)\n",
    "\n",
    "#Split training and test data\n",
    "grey_consonant_train, grey_consonant_test = split_data(grey_shuffled_consonants)\n",
    "grey_consonant_shape_labels_train, grey_consonant_shape_labels_test = split_data(grey_shuffled_consonant_shape_labels)\n",
    "grey_consonant_position_labels_train, grey_consonant_position_labels_test = split_data(grey_shuffled_consonant_position_labels)\n",
    "grey_consonant_phoneme_labels_train, grey_consonant_phoneme_labels_test = split_data(grey_shuffled_consonant_phoneme_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "43/43 [==============================] - 40s 932ms/step - loss: 1.9734 - accuracy: 0.2906\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 40s 935ms/step - loss: 1.5897 - accuracy: 0.4566\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 41s 950ms/step - loss: 1.1460 - accuracy: 0.6182\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 40s 937ms/step - loss: 0.8670 - accuracy: 0.7094\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 40s 936ms/step - loss: 0.6674 - accuracy: 0.7695\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dec9d65988>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build the network to recognise hand shape\n",
    "grey_hand_shape_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(256, 256, 1)),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(9, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compile the networ\n",
    "grey_hand_shape_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train the network\n",
    "grey_hand_shape_model.fit(grey_consonant_train, grey_consonant_shape_labels_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 267ms/step - loss: 0.9927 - accuracy: 0.7200\n",
      "Test loss: 0.992749810218811, Test accuracy: 72.00000286102295\n"
     ]
    }
   ],
   "source": [
    "#Test the network and print it's performance\n",
    "grey_hand_shape_test_loss, grey_hand_shape_test_accuracy = grey_hand_shape_model.evaluate(grey_consonant_test, grey_consonant_shape_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(grey_hand_shape_test_loss, grey_hand_shape_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "43/43 [==============================] - 40s 922ms/step - loss: 3.0013 - accuracy: 0.1216\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 41s 958ms/step - loss: 2.7865 - accuracy: 0.1646\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 42s 973ms/step - loss: 2.5386 - accuracy: 0.2572\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 41s 942ms/step - loss: 2.2788 - accuracy: 0.3573\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 41s 949ms/step - loss: 1.9612 - accuracy: 0.4173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1dec9dcaa48>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build network to recognise consonant phoneme\n",
    "grey_consonant_phoneme_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(256, 256, 1)),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(25, activation='softmax')\n",
    "])\n",
    "\n",
    "#Complie the network\n",
    "grey_consonant_phoneme_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train the network\n",
    "grey_consonant_phoneme_model.fit(grey_consonant_train, grey_consonant_phoneme_labels_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 280ms/step - loss: 2.2636 - accuracy: 0.4267\n",
      "Test loss: 2.263645648956299, Test accuracy: 42.66666769981384\n"
     ]
    }
   ],
   "source": [
    "#Test the network and print it's performance\n",
    "grey_consonant_phoneme_test_loss, grey_consonant_phoneme_test_accuracy = grey_consonant_phoneme_model.evaluate(grey_consonant_test, grey_consonant_phoneme_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(grey_consonant_phoneme_test_loss, grey_consonant_phoneme_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain decisions from both networks and concatenate into a single decision vector\n",
    "grey_hand_shape_decision = grey_hand_shape_model(grey_consonant_train)\n",
    "\n",
    "grey_consonant_phoneme_decision = grey_consonant_phoneme_model(grey_consonant_train)\n",
    "\n",
    "grey_consonant_decision = join_outputs(grey_hand_shape_decision, grey_consonant_phoneme_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain test vectors to test network on\n",
    "grey_hand_shape_decision_test = grey_hand_shape_model(grey_consonant_test)\n",
    "\n",
    "grey_consonant_phoneme_decision_test = grey_consonant_phoneme_model(grey_consonant_test)\n",
    "\n",
    "grey_consonant_decision_test = join_outputs(grey_hand_shape_decision_test, grey_consonant_phoneme_decision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 3.2502 - accuracy: 0.0645\n",
      "Epoch 2/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 3.0733 - accuracy: 0.1023\n",
      "Epoch 3/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.9590 - accuracy: 0.1023\n",
      "Epoch 4/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.8756 - accuracy: 0.1023\n",
      "Epoch 5/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.8073 - accuracy: 0.2350\n",
      "Epoch 6/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.7460 - accuracy: 0.2224\n",
      "Epoch 7/30\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 2.6860 - accuracy: 0.3225\n",
      "Epoch 8/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.6245 - accuracy: 0.4173\n",
      "Epoch 9/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.5609 - accuracy: 0.4233\n",
      "Epoch 10/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.4925 - accuracy: 0.4240\n",
      "Epoch 11/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.4197 - accuracy: 0.4240\n",
      "Epoch 12/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.3434 - accuracy: 0.4426\n",
      "Epoch 13/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.2628 - accuracy: 0.5011\n",
      "Epoch 14/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.1795 - accuracy: 0.5219\n",
      "Epoch 15/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.0949 - accuracy: 0.5597\n",
      "Epoch 16/30\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 2.0082 - accuracy: 0.5678\n",
      "Epoch 17/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.9218 - accuracy: 0.5693\n",
      "Epoch 18/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.8365 - accuracy: 0.5738\n",
      "Epoch 19/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.7523 - accuracy: 0.6190\n",
      "Epoch 20/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6697 - accuracy: 0.6635\n",
      "Epoch 21/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5905 - accuracy: 0.7220\n",
      "Epoch 22/30\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.5143 - accuracy: 0.7391\n",
      "Epoch 23/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4408 - accuracy: 0.7635\n",
      "Epoch 24/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3699 - accuracy: 0.7739\n",
      "Epoch 25/30\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.3029 - accuracy: 0.7769\n",
      "Epoch 26/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2380 - accuracy: 0.7932\n",
      "Epoch 27/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.1758 - accuracy: 0.8050\n",
      "Epoch 28/30\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.1172 - accuracy: 0.8087\n",
      "Epoch 29/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0611 - accuracy: 0.8139\n",
      "Epoch 30/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.0076 - accuracy: 0.8332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x18620eac448>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build network to make final decision of phoneme\n",
    "grey_consonant_decision_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(16, activation='sigmoid'),\n",
    "  tf.keras.layers.Dense(25, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compile network\n",
    "grey_consonant_decision_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train network\n",
    "grey_consonant_decision_model.fit(grey_consonant_decision, grey_consonant_phoneme_labels_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 1.8380 - accuracy: 0.4800\n",
      "Test loss: 1.8380109071731567, Test accuracy: 47.999998927116394\n"
     ]
    }
   ],
   "source": [
    "#Test network and print result\n",
    "grey_consonant_test_loss, grey_consonant_test_accuracy = grey_consonant_decision_model.evaluate(grey_consonant_decision_test, grey_consonant_phoneme_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(grey_consonant_test_loss, grey_consonant_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
