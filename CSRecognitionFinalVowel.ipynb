{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics, svm, naive_bayes\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract labels from files\n",
    "def extract_labels(file_path):\n",
    "    with open(file_path) as file_labels:\n",
    "\n",
    "        file_lines = file_labels.readlines()\n",
    "\n",
    "        file_shape_labels= [None] * len(file_lines)\n",
    "        file_position_labels = [None] * len(file_lines)\n",
    "        file_phoneme_labels = [None] * len(file_lines)\n",
    "        file_second_phoneme_label = [None] * len(file_lines)\n",
    "        \n",
    "        for i, line in enumerate(file_lines):\n",
    "            file_line = line.split()\n",
    "\n",
    "            file_shape_labels[i]  = int(file_line[1])\n",
    "            file_position_labels[i] = int(file_line[2])\n",
    "            file_phoneme_labels[i] = int(file_line[3])\n",
    "            file_second_phoneme_label[i] = int(file_line[4])\n",
    "            \n",
    "    return np.array(file_shape_labels), np.array(file_position_labels), np.array(file_phoneme_labels), np.array(file_second_phoneme_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funtion to randomly shuffle data\n",
    "def shuffle_data(images, shape_labels, position_labels, phoneme_labels, second_phoneme_labels):\n",
    "    #index = np.arange(len(labels))\n",
    "    #np.shuffle(index)\n",
    "    index = np.random.choice(np.arange(len(phoneme_labels)), replace = False, size = len(phoneme_labels))\n",
    "    \n",
    "    shuffled_images = images[index]\n",
    "    shuffled_shape_labels = shape_labels[index]\n",
    "    shuffled_position_labels = position_labels[index]\n",
    "    shuffled_phoneme_labels = phoneme_labels[index]\n",
    "    shuffled_second_phoneme_labels = second_phoneme_labels[index]\n",
    "    return shuffled_images, shuffled_shape_labels, shuffled_position_labels, shuffled_phoneme_labels, shuffled_second_phoneme_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to split data\n",
    "def split_data(data, split_ratio=0.9):\n",
    "    partition = round(len(data) * split_ratio)\n",
    "    \n",
    "    train = data[:partition]\n",
    "    test = data[partition:]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to prepare dataset to input network\n",
    "def create_dataset(image_dir):\n",
    "    dataset = []\n",
    "    for image_name in os.listdir(image_dir):\n",
    "        image = Image.open(image_dir + image_name)\n",
    "        image_as_array = np.asarray(image)\n",
    "        dataset.append(image_as_array)\n",
    "    return np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to concatenate outputs of two networks into single vector\n",
    "def join_outputs(out1, out2):\n",
    "    joint_output = []\n",
    "    for i in range(len(out1)):\n",
    "        joint = np.concatenate((out1[i],out2[i]))\n",
    "        joint_output.append(joint)\n",
    "    return np.array(joint_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot training and validation loss and accuracy\n",
    "#Obtained from https://www.tensorflow.org/tutorials/images/classification\n",
    "def plot_training_results(history, epochs = 7):\n",
    "    \n",
    "    loss=history.history['loss']\n",
    "    val_loss=history.history['val_loss']\n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the data augmentation layer that will go in at the start of the networks\n",
    "#Obtained from https://www.tensorflow.org/tutorials/images/classification\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    #tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\", input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1, input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open image folders\n",
    "consonants_dir = os.path.join('/Users/User/Desktop/MSc Project/English Cued Speech/ConsonantImages/')\n",
    "vowels_dir = os.path.join('/Users/User/Desktop/MSc Project/English Cued Speech/VowelImages/')\n",
    "combined_dir = os.path.join('/Users/User/Desktop/MSc Project/English Cued Speech/PhonemeImages/')\n",
    "\n",
    "#Open label files\n",
    "consonant_labels = \"/Users/User/Desktop/MSc Project/English Cued Speech/Labels_Consonant.txt\"\n",
    "vowel_labels = \"/Users/User/Desktop/MSc Project/English Cued Speech/Labels_Vowel.txt\"\n",
    "combined_labels = \"/Users/User/Desktop/MSc Project/English Cued Speech/Labels_All.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract labels\n",
    "(vowel_shape_labels, vowel_position_labels, vowel_phoneme_labels, not_used) = extract_labels(vowel_labels)\n",
    "(consonant_shape_labels, consonant_position_labels, consonant_phoneme_labels, or_this) = extract_labels(consonant_labels)\n",
    "(combined_shape_labels, combined_position_labels, combined_consonant_labels, combined_vowel_labels) = extract_labels(combined_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vowels Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare images of vowels to input into network\n",
    "vowel_images = create_dataset(vowels_dir)\n",
    "vowel_images = vowel_images.reshape(len(vowel_images), 256, 256, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly shuffle vowel images and labels\n",
    "shuffled_vowels, shuffled_vowel_shape_labels, shuffled_vowel_position_labels, shuffled_vowel_phoneme_labels, non_used = shuffle_data(vowel_images, vowel_shape_labels, vowel_position_labels, vowel_phoneme_labels, not_used)\n",
    "\n",
    "#Split training and test data\n",
    "vowel_train, vowel_test = split_data(shuffled_vowels)\n",
    "vowel_shape_labels_train, vowel_shape_labels_test = split_data(shuffled_vowel_shape_labels)\n",
    "vowel_position_labels_train, vowel_position_labels_test = split_data(shuffled_vowel_position_labels)\n",
    "vowel_phoneme_labels_train, vowel_phoneme_labels_test = split_data(shuffled_vowel_phoneme_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "33/33 [==============================] - 27s 810ms/step - loss: 1.7220 - accuracy: 0.6314\n",
      "Epoch 2/7\n",
      "33/33 [==============================] - 27s 827ms/step - loss: 0.2365 - accuracy: 0.9282\n",
      "Epoch 3/7\n",
      "33/33 [==============================] - 27s 826ms/step - loss: 0.1625 - accuracy: 0.9622\n",
      "Epoch 4/7\n",
      "33/33 [==============================] - 26s 787ms/step - loss: 0.1378 - accuracy: 0.9593\n",
      "Epoch 5/7\n",
      "33/33 [==============================] - 28s 847ms/step - loss: 0.1049 - accuracy: 0.9767\n",
      "Epoch 6/7\n",
      "33/33 [==============================] - 28s 839ms/step - loss: 0.0794 - accuracy: 0.9825\n",
      "Epoch 7/7\n",
      "33/33 [==============================] - 28s 856ms/step - loss: 0.0641 - accuracy: 0.9845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2107a692108>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build the network to recognise hand position\n",
    "hand_position_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(256, 256, 3)),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compile the network\n",
    "hand_position_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train the network\n",
    "hand_position_model.fit(vowel_train, vowel_position_labels_train, epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 266ms/step - loss: 0.1630 - accuracy: 0.9739\n",
      "Test loss: 0.16300436854362488, Test accuracy: 97.39130139350891\n"
     ]
    }
   ],
   "source": [
    "#Test the network and print it's performance\n",
    "hand_position_test_loss, hand_position_test_accuracy = hand_position_model.evaluate(vowel_test, vowel_position_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(hand_position_test_loss, hand_position_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "33/33 [==============================] - 61s 2s/step - loss: 1.6990 - accuracy: 0.4782\n",
      "Epoch 2/7\n",
      "33/33 [==============================] - 53s 2s/step - loss: 1.0189 - accuracy: 0.6353\n",
      "Epoch 3/7\n",
      "33/33 [==============================] - 48s 1s/step - loss: 0.8837 - accuracy: 0.6731\n",
      "Epoch 4/7\n",
      "33/33 [==============================] - 44s 1s/step - loss: 0.7706 - accuracy: 0.6848\n",
      "Epoch 5/7\n",
      "33/33 [==============================] - 44s 1s/step - loss: 0.6972 - accuracy: 0.7313\n",
      "Epoch 6/7\n",
      "33/33 [==============================] - 43s 1s/step - loss: 0.6344 - accuracy: 0.7352\n",
      "Epoch 7/7\n",
      "33/33 [==============================] - 44s 1s/step - loss: 0.6068 - accuracy: 0.7546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2101adef688>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build network to recognise vowel phoneme\n",
    "vowel_phoneme_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(256, 256, 3)),\n",
    "  tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(13, activation='softmax')\n",
    "])\n",
    "\n",
    "#Complie the network\n",
    "vowel_phoneme_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train the network\n",
    "vowel_phoneme_model.fit(vowel_train, vowel_phoneme_labels_train, epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_training_results(vowel_phoneme_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 299ms/step - loss: 1.1624 - accuracy: 0.5391\n",
      "Test loss: 1.1623965501785278, Test accuracy: 53.913044929504395\n"
     ]
    }
   ],
   "source": [
    "#Test the network and print it's performance\n",
    "vowel_phoneme_test_loss, vowel_phoneme_test_accuracy = vowel_phoneme_model.evaluate(vowel_test, vowel_phoneme_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(vowel_phoneme_test_loss, vowel_phoneme_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain decisions from both networks and concatenate into a single decision vector\n",
    "hand_position_decision = hand_position_model(vowel_train)\n",
    "\n",
    "vowel_phoneme_decision = vowel_phoneme_model(vowel_train)\n",
    "\n",
    "vowel_decision = join_outputs(hand_position_decision, vowel_phoneme_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain test vectors to test network on\n",
    "hand_position_decision_test = hand_position_model(vowel_test)\n",
    "\n",
    "vowel_phoneme_decision_test = vowel_phoneme_model(vowel_test)\n",
    "\n",
    "vowel_decision_test = join_outputs(hand_position_decision_test, vowel_phoneme_decision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.4685 - accuracy: 0.2134\n",
      "Epoch 2/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 2.3192 - accuracy: 0.5092\n",
      "Epoch 3/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 2.1415 - accuracy: 0.6266\n",
      "Epoch 4/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.9283 - accuracy: 0.6576\n",
      "Epoch 5/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.7061 - accuracy: 0.6586\n",
      "Epoch 6/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.5052 - accuracy: 0.6596\n",
      "Epoch 7/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.3447 - accuracy: 0.6596\n",
      "Epoch 8/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.2228 - accuracy: 0.6596\n",
      "Epoch 9/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.1278 - accuracy: 0.6625\n",
      "Epoch 10/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.0529 - accuracy: 0.6663\n",
      "Epoch 11/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.9912 - accuracy: 0.6663\n",
      "Epoch 12/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.9412 - accuracy: 0.6712\n",
      "Epoch 13/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.9000 - accuracy: 0.6780\n",
      "Epoch 14/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.8656 - accuracy: 0.6857\n",
      "Epoch 15/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.8355 - accuracy: 0.6896\n",
      "Epoch 16/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.8099 - accuracy: 0.6964\n",
      "Epoch 17/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.7882 - accuracy: 0.6984\n",
      "Epoch 18/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.7687 - accuracy: 0.7003\n",
      "Epoch 19/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.7514 - accuracy: 0.7003\n",
      "Epoch 20/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.7354 - accuracy: 0.7022\n",
      "Epoch 21/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.7209 - accuracy: 0.7100\n",
      "Epoch 22/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.7069 - accuracy: 0.7158\n",
      "Epoch 23/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6945 - accuracy: 0.7226\n",
      "Epoch 24/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6832 - accuracy: 0.7294\n",
      "Epoch 25/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.7371\n",
      "Epoch 26/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6603 - accuracy: 0.7430\n",
      "Epoch 27/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6497 - accuracy: 0.7449\n",
      "Epoch 28/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6406 - accuracy: 0.7459\n",
      "Epoch 29/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6315 - accuracy: 0.7585\n",
      "Epoch 30/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.6235 - accuracy: 0.7672\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2101cc31188>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build network to make final decision of phoneme\n",
    "vowel_decision_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(16, activation='relu'),\n",
    "  tf.keras.layers.Dense(13, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compile network\n",
    "vowel_decision_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train network\n",
    "vowel_decision_model.fit(vowel_decision, vowel_phoneme_labels_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 1.0235 - accuracy: 0.5739\n",
      "Test loss: 1.0235064029693604, Test accuracy: 57.3913037776947\n"
     ]
    }
   ],
   "source": [
    "#Test network and print result\n",
    "vowel_test_loss, vowel_test_accuracy = vowel_decision_model.evaluate(vowel_decision_test, vowel_phoneme_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(vowel_test_loss, vowel_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build SVM classifier for vowel\n",
    "vowel_svm = svm.SVC(kernel='linear')\n",
    "\n",
    "vowel_svm.fit(vowel_decision, vowel_phoneme_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 54.78260869565217\n"
     ]
    }
   ],
   "source": [
    "#Test SVM classifier and print accuracy\n",
    "svm_vowel_decision = vowel_svm.predict(vowel_decision_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(vowel_phoneme_labels_test, svm_vowel_decision)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build Naive-Bayes classifier for vowel\n",
    "vowel_nb = naive_bayes.GaussianNB()\n",
    "\n",
    "vowel_nb.fit(vowel_decision, vowel_phoneme_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 46.95652173913044\n"
     ]
    }
   ],
   "source": [
    "#Test Naive-Bayes classifier and print accuracy\n",
    "nb_vowel_decision = vowel_nb.predict(vowel_decision_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(vowel_phoneme_labels_test, nb_vowel_decision)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
