{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics, svm, naive_bayes\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract labels from files\n",
    "def extract_labels(file_path):\n",
    "    with open(file_path) as file_labels:\n",
    "\n",
    "        file_lines = file_labels.readlines()\n",
    "\n",
    "        file_shape_labels= [None] * len(file_lines)\n",
    "        file_position_labels = [None] * len(file_lines)\n",
    "        file_phoneme_labels = [None] * len(file_lines)\n",
    "        file_second_phoneme_label = [None] * len(file_lines)\n",
    "        \n",
    "        for i, line in enumerate(file_lines):\n",
    "            file_line = line.split()\n",
    "\n",
    "            file_shape_labels[i]  = int(file_line[1])\n",
    "            file_position_labels[i] = int(file_line[2])\n",
    "            file_phoneme_labels[i] = int(file_line[3])\n",
    "            file_second_phoneme_label[i] = int(file_line[4])\n",
    "            \n",
    "    return np.array(file_shape_labels), np.array(file_position_labels), np.array(file_phoneme_labels), np.array(file_second_phoneme_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funtion to randomly shuffle data\n",
    "def shuffle_data(images, shape_labels, position_labels, phoneme_labels, second_phoneme_labels):\n",
    "    #index = np.arange(len(labels))\n",
    "    #np.shuffle(index)\n",
    "    index = np.random.choice(np.arange(len(phoneme_labels)), replace = False, size = len(phoneme_labels))\n",
    "    \n",
    "    shuffled_images = images[index]\n",
    "    shuffled_shape_labels = shape_labels[index]\n",
    "    shuffled_position_labels = position_labels[index]\n",
    "    shuffled_phoneme_labels = phoneme_labels[index]\n",
    "    shuffled_second_phoneme_labels = second_phoneme_labels[index]\n",
    "    return shuffled_images, shuffled_shape_labels, shuffled_position_labels, shuffled_phoneme_labels, shuffled_second_phoneme_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to split data\n",
    "def split_data(data, split_ratio=0.9):\n",
    "    partition = round(len(data) * split_ratio)\n",
    "    \n",
    "    train = data[:partition]\n",
    "    test = data[partition:]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to prepare dataset as grey images to input network\n",
    "def create_grey_dataset(image_dir):\n",
    "    grey_dataset = []\n",
    "    for image_name in os.listdir(image_dir):\n",
    "        image = Image.open(image_dir + image_name)\n",
    "        image_as_array = np.asarray(image)\n",
    "        r, g, b = image_as_array[:,:,0], image_as_array[:,:,1], image_as_array[:,:,2]\n",
    "        grey_image = (0.3*r) + (0.59*g) +(0.11*b)\n",
    "        grey_dataset.append(grey_image)\n",
    "    return np.array(grey_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to concatenate outputs of two networks into single vector\n",
    "def join_outputs(out1, out2):\n",
    "    joint_output = []\n",
    "    for i in range(len(out1)):\n",
    "        joint = np.concatenate((out1[i],out2[i]))\n",
    "        joint_output.append(joint)\n",
    "    return np.array(joint_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot training and validation loss and accuracy\n",
    "#Obtained from https://www.tensorflow.org/tutorials/images/classification\n",
    "def plot_training_results(history, epochs = 5):\n",
    "    \n",
    "    loss=history.history['loss']\n",
    "    val_loss=history.history['val_loss']\n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open image folders\n",
    "consonants_dir = os.path.join('/Users/User/Desktop/MSc Project/English Cued Speech/ConsonantImages/')\n",
    "vowels_dir = os.path.join('/Users/User/Desktop/MSc Project/English Cued Speech/VowelImages/')\n",
    "combined_dir = os.path.join('/Users/User/Desktop/MSc Project/English Cued Speech/PhonemeImages/')\n",
    "\n",
    "#Open label files\n",
    "consonant_labels = \"/Users/User/Desktop/MSc Project/English Cued Speech/Labels_Consonant.txt\"\n",
    "vowel_labels = \"/Users/User/Desktop/MSc Project/English Cued Speech/Labels_Vowel.txt\"\n",
    "combined_labels = \"/Users/User/Desktop/MSc Project/English Cued Speech/Labels_All.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract labels\n",
    "(vowel_shape_labels, vowel_position_labels, vowel_phoneme_labels, not_used) = extract_labels(vowel_labels)\n",
    "(consonant_shape_labels, consonant_position_labels, consonant_phoneme_labels, or_this) = extract_labels(consonant_labels)\n",
    "(combined_shape_labels, combined_position_labels, combined_consonant_labels, combined_vowel_labels) = extract_labels(combined_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grey Vowels Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert images of consonants to greyscale and prepare to input into network\n",
    "grey_vowel_images = create_grey_dataset(vowels_dir)\n",
    "grey_vowel_images = grey_vowel_images.reshape(len(grey_vowel_images), 256, 256, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly shuffle consonant images and labels\n",
    "grey_shuffled_vowels, grey_shuffled_vowel_shape_labels, grey_shuffled_vowel_position_labels, grey_shuffled_vowel_phoneme_labels, grey_non_used = shuffle_data(grey_vowel_images, vowel_shape_labels, vowel_position_labels, vowel_phoneme_labels, not_used)\n",
    "\n",
    "#Split training and test data\n",
    "grey_vowel_train, grey_vowel_test = split_data(grey_shuffled_vowels)\n",
    "grey_vowel_shape_labels_train, grey_vowel_shape_labels_test = split_data(grey_shuffled_vowel_shape_labels)\n",
    "grey_vowel_position_labels_train, grey_vowel_position_labels_test = split_data(grey_shuffled_vowel_position_labels)\n",
    "grey_vowel_phoneme_labels_train, grey_vowel_phoneme_labels_test = split_data(grey_shuffled_vowel_phoneme_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "33/33 [==============================] - 32s 961ms/step - loss: 0.6519 - accuracy: 0.7672\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 31s 948ms/step - loss: 0.2453 - accuracy: 0.9243\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 32s 957ms/step - loss: 0.1449 - accuracy: 0.9631\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 30s 910ms/step - loss: 0.1096 - accuracy: 0.9719\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 32s 964ms/step - loss: 0.0863 - accuracy: 0.9835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b9e0c7d448>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build the network to recognise hand position\n",
    "grey_hand_position_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(256, 256, 1)),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(9, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compile the networ\n",
    "grey_hand_position_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train the network\n",
    "grey_hand_position_model.fit(grey_vowel_train, grey_vowel_position_labels_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 237ms/step - loss: 0.1382 - accuracy: 0.9826\n",
      "Test loss: 0.1381930559873581, Test accuracy: 98.26086759567261\n"
     ]
    }
   ],
   "source": [
    "#Test the network and print it's performance\n",
    "grey_hand_position_test_loss, grey_hand_position_test_accuracy = grey_hand_position_model.evaluate(grey_vowel_test, grey_vowel_position_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(grey_hand_position_test_loss, grey_hand_position_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "33/33 [==============================] - 32s 969ms/step - loss: 1.8379 - accuracy: 0.5063\n",
      "Epoch 2/5\n",
      "33/33 [==============================] - 31s 930ms/step - loss: 1.1203 - accuracy: 0.6237\n",
      "Epoch 3/5\n",
      "33/33 [==============================] - 30s 915ms/step - loss: 0.9301 - accuracy: 0.6625\n",
      "Epoch 4/5\n",
      "33/33 [==============================] - 31s 929ms/step - loss: 0.8245 - accuracy: 0.7129\n",
      "Epoch 5/5\n",
      "33/33 [==============================] - 30s 917ms/step - loss: 0.7351 - accuracy: 0.7139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b9e0db3708>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build network to recognise vowel phoneme\n",
    "grey_vowel_phoneme_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(256, 256, 1)),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(25, activation='softmax')\n",
    "])\n",
    "\n",
    "#Complie the network\n",
    "grey_vowel_phoneme_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train the network\n",
    "grey_vowel_phoneme_model.fit(grey_vowel_train, grey_vowel_phoneme_labels_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 254ms/step - loss: 1.0889 - accuracy: 0.5913\n",
      "Test loss: 1.0889414548873901, Test accuracy: 59.130436182022095\n"
     ]
    }
   ],
   "source": [
    "#Test the network and print it's performance\n",
    "grey_vowel_phoneme_test_loss, grey_vowel_phoneme_test_accuracy = grey_vowel_phoneme_model.evaluate(grey_vowel_test, grey_vowel_phoneme_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(grey_vowel_phoneme_test_loss, grey_vowel_phoneme_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain decisions from both networks and concatenate into a single decision vector\n",
    "grey_hand_position_decision = grey_hand_position_model(grey_vowel_train)\n",
    "\n",
    "grey_vowel_phoneme_decision = grey_vowel_phoneme_model(grey_vowel_train)\n",
    "\n",
    "grey_vowel_decision = join_outputs(grey_hand_position_decision, grey_vowel_phoneme_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain test vectors to test network on\n",
    "grey_hand_position_decision_test = grey_hand_position_model(grey_vowel_test)\n",
    "\n",
    "grey_vowel_phoneme_decision_test = grey_vowel_phoneme_model(grey_vowel_test)\n",
    "\n",
    "grey_vowel_decision_test = join_outputs(grey_hand_position_decision_test, grey_vowel_phoneme_decision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 3.1442 - accuracy: 0.0873\n",
      "Epoch 2/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 2.9739 - accuracy: 0.2357\n",
      "Epoch 3/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 2.7386 - accuracy: 0.4607\n",
      "Epoch 4/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 2.4316 - accuracy: 0.4597\n",
      "Epoch 5/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 2.0889 - accuracy: 0.5199\n",
      "Epoch 6/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.7834 - accuracy: 0.6295\n",
      "Epoch 7/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.5529 - accuracy: 0.6440\n",
      "Epoch 8/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.3922 - accuracy: 0.6499\n",
      "Epoch 9/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.2752 - accuracy: 0.6508\n",
      "Epoch 10/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 1.1879 - accuracy: 0.6518\n",
      "Epoch 11/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.1197 - accuracy: 0.6518\n",
      "Epoch 12/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.0646 - accuracy: 0.6518\n",
      "Epoch 13/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 1.0201 - accuracy: 0.6518\n",
      "Epoch 14/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.9833 - accuracy: 0.6518\n",
      "Epoch 15/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.9510 - accuracy: 0.6518\n",
      "Epoch 16/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.9239 - accuracy: 0.6518\n",
      "Epoch 17/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.9000 - accuracy: 0.6557\n",
      "Epoch 18/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.8791 - accuracy: 0.6693\n",
      "Epoch 19/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.8606 - accuracy: 0.6799\n",
      "Epoch 20/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.8436 - accuracy: 0.6857\n",
      "Epoch 21/30\n",
      "33/33 [==============================] - 0s 2ms/step - loss: 0.8289 - accuracy: 0.6906\n",
      "Epoch 22/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.8145 - accuracy: 0.6974\n",
      "Epoch 23/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.8036 - accuracy: 0.7013\n",
      "Epoch 24/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.7908 - accuracy: 0.7013\n",
      "Epoch 25/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.7799 - accuracy: 0.7071\n",
      "Epoch 26/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.7705 - accuracy: 0.7119\n",
      "Epoch 27/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.7602 - accuracy: 0.7110\n",
      "Epoch 28/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.7517 - accuracy: 0.7129\n",
      "Epoch 29/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.7428 - accuracy: 0.7168\n",
      "Epoch 30/30\n",
      "33/33 [==============================] - 0s 1ms/step - loss: 0.7364 - accuracy: 0.7216\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b9aec2e208>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build network to make final decision of phoneme\n",
    "grey_vowel_decision_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(16, activation='relu'),\n",
    "  tf.keras.layers.Dense(25, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compile network\n",
    "grey_vowel_decision_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train network\n",
    "grey_vowel_decision_model.fit(grey_vowel_decision, grey_vowel_phoneme_labels_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/4 [======>.......................] - ETA: 0s - loss: 1.0629 - accuracy: 0.5938WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0041s). Check your callbacks.\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.9820 - accuracy: 0.6000\n",
      "Test loss: 0.9820446372032166, Test accuracy: 60.00000238418579\n"
     ]
    }
   ],
   "source": [
    "#Test network and print result\n",
    "grey_vowel_test_loss, grey_vowel_test_accuracy = grey_vowel_decision_model.evaluate(grey_vowel_decision_test, grey_vowel_phoneme_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(grey_vowel_test_loss, grey_vowel_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build SVM classifier for vowel\n",
    "vowel_svm = svm.SVC(kernel='linear')\n",
    "\n",
    "vowel_svm.fit(grey_vowel_decision, grey_vowel_phoneme_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test SVM classifier and print accuracy\n",
    "svm_vowel_decision = vowel_svm.predict(grey_vowel_decision_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(grey_vowel_phoneme_labels_test, svm_vowel_decision)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build Naive-Bayes classifier for vowel\n",
    "vowel_nb = naive_bayes.GaussianNB()\n",
    "\n",
    "vowel_nb.fit(grey_vowel_decision, grey_vowel_phoneme_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Naive-Bayes classifier and print accuracy\n",
    "nb_vowel_decision = vowel_nb.predict(grey_vowel_decision_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(grey_vowel_phoneme_labels_test, nb_vowel_decision)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
