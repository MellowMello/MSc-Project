{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics, svm, naive_bayes\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to extract labels from files\n",
    "def extract_labels(file_path):\n",
    "    with open(file_path) as file_labels:\n",
    "\n",
    "        file_lines = file_labels.readlines()\n",
    "\n",
    "        file_shape_labels= [None] * len(file_lines)\n",
    "        file_position_labels = [None] * len(file_lines)\n",
    "        file_phoneme_labels = [None] * len(file_lines)\n",
    "        file_second_phoneme_label = [None] * len(file_lines)\n",
    "        \n",
    "        for i, line in enumerate(file_lines):\n",
    "            file_line = line.split()\n",
    "\n",
    "            file_shape_labels[i]  = int(file_line[1])\n",
    "            file_position_labels[i] = int(file_line[2])\n",
    "            file_phoneme_labels[i] = int(file_line[3])\n",
    "            file_second_phoneme_label[i] = int(file_line[4])\n",
    "            \n",
    "    return np.array(file_shape_labels), np.array(file_position_labels), np.array(file_phoneme_labels), np.array(file_second_phoneme_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funtion to randomly shuffle data\n",
    "def shuffle_data(images, shape_labels, position_labels, phoneme_labels, second_phoneme_labels):\n",
    "    #index = np.arange(len(labels))\n",
    "    #np.shuffle(index)\n",
    "    index = np.random.choice(np.arange(len(phoneme_labels)), replace = False, size = len(phoneme_labels))\n",
    "    \n",
    "    shuffled_images = images[index]\n",
    "    shuffled_shape_labels = shape_labels[index]\n",
    "    shuffled_position_labels = position_labels[index]\n",
    "    shuffled_phoneme_labels = phoneme_labels[index]\n",
    "    shuffled_second_phoneme_labels = second_phoneme_labels[index]\n",
    "    return shuffled_images, shuffled_shape_labels, shuffled_position_labels, shuffled_phoneme_labels, shuffled_second_phoneme_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to split data\n",
    "def split_data(data, split_ratio=0.9):\n",
    "    partition = round(len(data) * split_ratio)\n",
    "    \n",
    "    train = data[:partition]\n",
    "    test = data[partition:]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to prepare dataset as grey images to input network\n",
    "def create_grey_dataset(image_dir):\n",
    "    grey_dataset = []\n",
    "    for image_name in os.listdir(image_dir):\n",
    "        image = Image.open(image_dir + image_name)\n",
    "        image_as_array = np.asarray(image)\n",
    "        r, g, b = image_as_array[:,:,0], image_as_array[:,:,1], image_as_array[:,:,2]\n",
    "        grey_image = (0.3*r) + (0.59*g) +(0.11*b)\n",
    "        grey_dataset.append(grey_image)\n",
    "    return np.array(grey_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to concatenate outputs of two networks into single vector\n",
    "def join_outputs(out1, out2):\n",
    "    joint_output = []\n",
    "    for i in range(len(out1)):\n",
    "        joint = np.concatenate((out1[i],out2[i]))\n",
    "        joint_output.append(joint)\n",
    "    return np.array(joint_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to plot training and validation loss and accuracy\n",
    "#Obtained from https://www.tensorflow.org/tutorials/images/classification\n",
    "def plot_training_results(history, epochs = 5):\n",
    "    \n",
    "    loss=history.history['loss']\n",
    "    val_loss=history.history['val_loss']\n",
    "    \n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "\n",
    "    epochs_range = range(epochs)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs_range, loss, label='Training Loss')\n",
    "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Training and Validation Accuracy')\n",
    "\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open image folders\n",
    "consonants_dir = os.path.join('/Users/User/Desktop/MSc Project/English Cued Speech/ConsonantImages/')\n",
    "vowels_dir = os.path.join('/Users/User/Desktop/MSc Project/English Cued Speech/VowelImages/')\n",
    "combined_dir = os.path.join('/Users/User/Desktop/MSc Project/English Cued Speech/PhonemeImages/')\n",
    "\n",
    "#Open label files\n",
    "consonant_labels = \"/Users/User/Desktop/MSc Project/English Cued Speech/Labels_Consonant.txt\"\n",
    "vowel_labels = \"/Users/User/Desktop/MSc Project/English Cued Speech/Labels_Vowel.txt\"\n",
    "combined_labels = \"/Users/User/Desktop/MSc Project/English Cued Speech/Labels_All.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract labels\n",
    "(vowel_shape_labels, vowel_position_labels, vowel_phoneme_labels, not_used) = extract_labels(vowel_labels)\n",
    "(consonant_shape_labels, consonant_position_labels, consonant_phoneme_labels, or_this) = extract_labels(consonant_labels)\n",
    "(combined_shape_labels, combined_position_labels, combined_consonant_labels, combined_vowel_labels) = extract_labels(combined_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grey Consonants Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert images of consonants to greyscale and prepare to input into network\n",
    "grey_consonant_images = create_grey_dataset(consonants_dir)\n",
    "grey_consonant_images = grey_consonant_images.reshape(len(grey_consonant_images), 256, 256, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomly shuffle consonant images and labels\n",
    "grey_shuffled_consonants, grey_shuffled_consonant_shape_labels, grey_shuffled_consonant_position_labels, grey_shuffled_consonant_phoneme_labels, grey_nor_this = shuffle_data(grey_consonant_images, consonant_shape_labels, consonant_position_labels, consonant_phoneme_labels, or_this)\n",
    "\n",
    "#Split training and test data\n",
    "grey_consonant_train, grey_consonant_test = split_data(grey_shuffled_consonants)\n",
    "grey_consonant_shape_labels_train, grey_consonant_shape_labels_test = split_data(grey_shuffled_consonant_shape_labels)\n",
    "grey_consonant_position_labels_train, grey_consonant_position_labels_test = split_data(grey_shuffled_consonant_position_labels)\n",
    "grey_consonant_phoneme_labels_train, grey_consonant_phoneme_labels_test = split_data(grey_shuffled_consonant_phoneme_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "43/43 [==============================] - 40s 936ms/step - loss: 1.9867 - accuracy: 0.2246\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 41s 948ms/step - loss: 1.7503 - accuracy: 0.3684\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 40s 933ms/step - loss: 1.4320 - accuracy: 0.5226\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 41s 949ms/step - loss: 1.1139 - accuracy: 0.6368\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 41s 955ms/step - loss: 0.8265 - accuracy: 0.7354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b9e0f5f548>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build the network to recognise hand shape\n",
    "grey_hand_shape_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(256, 256, 1)),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(9, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compile the networ\n",
    "grey_hand_shape_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train the network\n",
    "grey_hand_shape_model.fit(grey_consonant_train, grey_consonant_shape_labels_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 271ms/step - loss: 1.0187 - accuracy: 0.6333\n",
      "Test loss: 1.0186818838119507, Test accuracy: 63.333332538604736\n"
     ]
    }
   ],
   "source": [
    "#Test the network and print it's performance\n",
    "grey_hand_shape_test_loss, grey_hand_shape_test_accuracy = grey_hand_shape_model.evaluate(grey_consonant_test, grey_consonant_shape_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(grey_hand_shape_test_loss, grey_hand_shape_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "43/43 [==============================] - 40s 928ms/step - loss: 2.9621 - accuracy: 0.1119\n",
      "Epoch 2/5\n",
      "43/43 [==============================] - 41s 942ms/step - loss: 2.6837 - accuracy: 0.2187\n",
      "Epoch 3/5\n",
      "43/43 [==============================] - 40s 924ms/step - loss: 2.4077 - accuracy: 0.3262\n",
      "Epoch 4/5\n",
      "43/43 [==============================] - 40s 940ms/step - loss: 2.0682 - accuracy: 0.4114\n",
      "Epoch 5/5\n",
      "43/43 [==============================] - 41s 946ms/step - loss: 1.7353 - accuracy: 0.4885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b9aeaee988>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build network to recognise consonant phoneme\n",
    "grey_consonant_phoneme_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.experimental.preprocessing.Rescaling(1./255, input_shape=(256, 256, 1)),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2, 2),\n",
    "  tf.keras.layers.Conv2D(8, (3, 3), activation='relu'),\n",
    "  tf.keras.layers.MaxPooling2D(2,2),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dense(25, activation='softmax')\n",
    "])\n",
    "\n",
    "#Complie the network\n",
    "grey_consonant_phoneme_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train the network\n",
    "grey_consonant_phoneme_model.fit(grey_consonant_train, grey_consonant_phoneme_labels_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 270ms/step - loss: 2.1323 - accuracy: 0.3667\n",
      "Test loss: 2.132263660430908, Test accuracy: 36.666667461395264\n"
     ]
    }
   ],
   "source": [
    "#Test the network and print it's performance\n",
    "grey_consonant_phoneme_test_loss, grey_consonant_phoneme_test_accuracy = grey_consonant_phoneme_model.evaluate(grey_consonant_test, grey_consonant_phoneme_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(grey_consonant_phoneme_test_loss, grey_consonant_phoneme_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain decisions from both networks and concatenate into a single decision vector\n",
    "grey_hand_shape_decision = grey_hand_shape_model(grey_consonant_train)\n",
    "\n",
    "grey_consonant_phoneme_decision = grey_consonant_phoneme_model(grey_consonant_train)\n",
    "\n",
    "grey_consonant_decision = join_outputs(grey_hand_shape_decision, grey_consonant_phoneme_decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain test vectors to test network on\n",
    "grey_hand_shape_decision_test = grey_hand_shape_model(grey_consonant_test)\n",
    "\n",
    "grey_consonant_phoneme_decision_test = grey_consonant_phoneme_model(grey_consonant_test)\n",
    "\n",
    "grey_consonant_decision_test = join_outputs(grey_hand_shape_decision_test, grey_consonant_phoneme_decision_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 3.1596 - accuracy: 0.0726\n",
      "Epoch 2/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 3.0519 - accuracy: 0.1534\n",
      "Epoch 3/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.9128 - accuracy: 0.2380\n",
      "Epoch 4/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.7441 - accuracy: 0.3269\n",
      "Epoch 5/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.5669 - accuracy: 0.4047\n",
      "Epoch 6/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.3940 - accuracy: 0.4211\n",
      "Epoch 7/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.2329 - accuracy: 0.4344\n",
      "Epoch 8/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 2.0910 - accuracy: 0.4255\n",
      "Epoch 9/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.9708 - accuracy: 0.4618\n",
      "Epoch 10/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.8716 - accuracy: 0.4685\n",
      "Epoch 11/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.7922 - accuracy: 0.4737\n",
      "Epoch 12/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.7224 - accuracy: 0.4878\n",
      "Epoch 13/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.6643 - accuracy: 0.4989\n",
      "Epoch 14/30\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.6147 - accuracy: 0.4959\n",
      "Epoch 15/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5710 - accuracy: 0.4996\n",
      "Epoch 16/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.5327 - accuracy: 0.5107\n",
      "Epoch 17/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4982 - accuracy: 0.5137\n",
      "Epoch 18/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4685 - accuracy: 0.5315\n",
      "Epoch 19/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4409 - accuracy: 0.5397\n",
      "Epoch 20/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.4164 - accuracy: 0.5582\n",
      "Epoch 21/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3925 - accuracy: 0.5612\n",
      "Epoch 22/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3725 - accuracy: 0.5656\n",
      "Epoch 23/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3537 - accuracy: 0.5834\n",
      "Epoch 24/30\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.3356 - accuracy: 0.5827\n",
      "Epoch 25/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3200 - accuracy: 0.5856\n",
      "Epoch 26/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.3039 - accuracy: 0.5945\n",
      "Epoch 27/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2914 - accuracy: 0.5975\n",
      "Epoch 28/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2794 - accuracy: 0.5967\n",
      "Epoch 29/30\n",
      "43/43 [==============================] - 0s 2ms/step - loss: 1.2663 - accuracy: 0.5997\n",
      "Epoch 30/30\n",
      "43/43 [==============================] - 0s 1ms/step - loss: 1.2558 - accuracy: 0.5982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b9aec45248>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build network to make final decision of phoneme\n",
    "grey_consonant_decision_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(16, activation='relu'),\n",
    "  tf.keras.layers.Dense(25, activation='softmax')\n",
    "])\n",
    "\n",
    "#Compile network\n",
    "grey_consonant_decision_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train network\n",
    "grey_consonant_decision_model.fit(grey_consonant_decision, grey_consonant_phoneme_labels_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 2ms/step - loss: 1.7051 - accuracy: 0.4200\n",
      "Test loss: 1.70505952835083, Test accuracy: 41.999998688697815\n"
     ]
    }
   ],
   "source": [
    "#Test network and print result\n",
    "grey_consonant_test_loss, grey_consonant_test_accuracy = grey_consonant_decision_model.evaluate(grey_consonant_decision_test, grey_consonant_phoneme_labels_test)\n",
    "print ('Test loss: {}, Test accuracy: {}'.format(grey_consonant_test_loss, grey_consonant_test_accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build SVM classifier for consonant\n",
    "consonant_svm = svm.SVC(kernel='linear')\n",
    "\n",
    "consonant_svm.fit(grey_consonant_decision, grey_consonant_phoneme_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test SVM classifier and print accuracy\n",
    "svm_consonant_decision = consonant_svm.predict(grey_consonant_decision_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(grey_consonant_phoneme_labels_test, svm_consonant_decision)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Build Naive-Bayes classifier for consonant\n",
    "consonant_nb = naive_bayes.GaussianNB()\n",
    "\n",
    "consonant_nb.fit(grey_consonant_decision, grey_consonant_phoneme_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Naive-Bayes classifier and print accuracy\n",
    "nb_consonant_decision = consonant_nb.predict(grey_consonant_decision_test)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(grey_consonant_phoneme_labels_test, nb_consonant_decision)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
